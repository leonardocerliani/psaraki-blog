[
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html",
    "href": "posts/purrr_RManova/purrr_RManova.html",
    "title": "How to replace for loops using purrr::map",
    "section": "",
    "text": "In many cases you need to repeat the same action across multiple objects, for instance loading many files, or computing summary statistics across many vectors of observations. Instead of repeating the same operation manually for every object - which is not only time consuming, but especially prone to mistakes - you can use for loops.\nHowever for can be quite verbose, and especially in case you need to nest them - i.e. running a loop inside a loop - it can be difficult to inspect the code for errors during the analysis and especially in the future.\nBase R already provides some functions to avoid the creation of for loops, with the family of apply functions. However sometimes the syntax can be different across functions, and still a bit verbose.\nThe tidyverse provides functions that help getting rid of for loops for good using the purrr package. Below there is just an example. More details can be found in the iteration chapter of R for Data Science and in the functionals chapter of Advanced R\n\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(DT)\noptions(digits=2)\n\nLet’s say you collected data in 8 different runs of an experiment. For instance the time, in seconds, spent freezing, running or grooming in 10 participants after a given stimulus in each subsequent run.\nFor our example we will create some random data. The code below creates 8 dataframes with 10 observations for three distinct variables. It already uses the map function that we are going to explain later, so for now you can just disregard it, and come back later to understand what it does as an excercise.\n\n1:8 %>% map( function(x) {\n  tibble(\n    SUBID = map(1:10, ~ paste0(\"sub_\",.x) ) %>% unlist(),\n    freezing = runif(10)*10 * log(x+1),\n    running = runif(10)*10,\n    grooming = runif(10)*10\n  ) %>%\n    write_csv(paste0(\"run_\",x,\".csv\"))\n})\n\nWe obtain 8 csv files with our data.\n\nmyfiles <- list.files(pattern = \".csv\", full.names = T)\nmyfiles\n\n[1] \"./run_1.csv\" \"./run_2.csv\" \"./run_3.csv\" \"./run_4.csv\" \"./run_5.csv\"\n[6] \"./run_6.csv\" \"./run_7.csv\" \"./run_8.csv\"\n\nread.csv(\"run_1.csv\")\n\n    SUBID freezing running grooming\n1   sub_1     3.40   0.438      4.1\n2   sub_2     6.49   5.871      7.5\n3   sub_3     2.95   7.872      6.8\n4   sub_4     4.72   0.678      1.4\n5   sub_5     2.64   6.816      2.2\n6   sub_6     5.28   4.391      7.1\n7   sub_7     3.46   0.070      9.9\n8   sub_8     0.77   8.778      5.6\n9   sub_9     4.78   7.170      8.8\n10 sub_10     3.32   0.055      8.9"
  },
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html#purrrmap",
    "href": "posts/purrr_RManova/purrr_RManova.html#purrrmap",
    "title": "How to replace for loops using purrr::map",
    "section": "purrr::map",
    "text": "purrr::map\nNow you want to load everything in the same dataframe (i.e. table), for instance to carry out a RM-ANOVA. You could use a for loop to load all the files:\n\nallruns = vector(mode = \"list\", length = 8)\n\nfor (run in 1:length(allruns)) {\n  allruns[[run]] <- read.csv( myfiles[[run]] )\n}\n\n# allruns\n\nOr you could use the map function inside the purrr package\n\nallruns <- map(myfiles, read.csv)\n\n# allruns\n\nIn other words you passed to every element of the list myfiles the function read.csv\nNote the advantages:\n\nyou do not need to write extra code to initialize an empty list, since the result is automatically stored in a list\nyou don’t need to provide the total number of files,\nthe syntax is much more concise (and when you get used to it, also much more readable)."
  },
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html#purrrmap2",
    "href": "posts/purrr_RManova/purrr_RManova.html#purrrmap2",
    "title": "How to replace for loops using purrr::map",
    "section": "purrr::map2",
    "text": "purrr::map2\nTo carry out the RM-ANOVA, you need to combine all the tables into one singe dataframe, but also retain information about the different run.\nThe idea is the same as before: you have a function that creates a column with the run numba in each run’s data table. This means that you want to provide two lists: (1) the list containing the table of each run and (2) the list of filenames.\n\nalldata <- map2(allruns, myfiles, function(run, file) run %>% mutate(run = file)) %>% bind_rows()\n\nor with a more concise syntax:\n\nalldata <- map2_df(allruns, myfiles, ~ .x %>% mutate(run = .y))\n\nYou might have noticed that here I used a specific flavor of map, that is map_df, which returns a dataframe (or a tibble in the tidyverse language) instead of the default list, so that I can drop the final bind_rows()."
  },
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html#purrrpmap",
    "href": "posts/purrr_RManova/purrr_RManova.html#purrrpmap",
    "title": "How to replace for loops using purrr::map",
    "section": "purrr::pmap",
    "text": "purrr::pmap\nAs you might expect, there is also a function pmap which allows you to pass an arbitrary number of tables. I personally prefer this syntax since it allows me to pipe the list into it:\n\nalldata <- list(allruns, myfiles) %>% pmap_df(~ .x %>% mutate(run = .y))\n\n\ndatatable(alldata, options = list(dom = 'tp', scrollX = TRUE)) %>%\n  DT::formatRound(\n    columns = alldata %>% select(where(is.numeric)) %>% colnames(), \n    digits=2\n  )"
  },
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html#map-is-similar-to-group_by-for-dataframes",
    "href": "posts/purrr_RManova/purrr_RManova.html#map-is-similar-to-group_by-for-dataframes",
    "title": "How to replace for loops using purrr::map",
    "section": "map is similar to group_by for dataframes",
    "text": "map is similar to group_by for dataframes\nFinally, note that the map function - and its variation, such as pmap, is a similar operator for list to the group_by operator inside dataframes.\nFor instance let’s say that you want to get the mean and standard deviation for every variable in each run:\n\ndescriptives <- alldata %>% \n  group_by(run) %>%\n  summarise(\n    across(where(is.numeric), list(mean = mean, sd = sd)),\n    .groups = \"drop\"\n  ) %>% ungroup() \n\n\ndescriptives %>% \n  kbl() %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\n \n  \n    run \n    freezing_mean \n    freezing_sd \n    running_mean \n    running_sd \n    grooming_mean \n    grooming_sd \n  \n \n\n  \n    ./run_1.csv \n    3.8 \n    1.6 \n    4.2 \n    3.5 \n    6.2 \n    2.9 \n  \n  \n    ./run_2.csv \n    4.3 \n    2.5 \n    6.3 \n    2.4 \n    3.6 \n    2.1 \n  \n  \n    ./run_3.csv \n    7.0 \n    4.1 \n    4.8 \n    2.7 \n    6.4 \n    3.0 \n  \n  \n    ./run_4.csv \n    10.9 \n    3.3 \n    3.9 \n    2.7 \n    3.3 \n    2.2 \n  \n  \n    ./run_5.csv \n    8.7 \n    4.0 \n    4.9 \n    2.7 \n    4.4 \n    2.7 \n  \n  \n    ./run_6.csv \n    7.8 \n    5.0 \n    6.2 \n    2.1 \n    4.4 \n    2.2 \n  \n  \n    ./run_7.csv \n    9.7 \n    5.8 \n    3.7 \n    2.3 \n    6.4 \n    2.6 \n  \n  \n    ./run_8.csv \n    13.2 \n    5.9 \n    3.3 \n    2.8 \n    5.4 \n    3.4"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "It is time to make a blog…",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LC",
    "section": "",
    "text": "leonardo cerliani\nneuroimaging data analyst"
  },
  {
    "objectID": "apps.html",
    "href": "apps.html",
    "title": "Shiny apps",
    "section": "",
    "text": "Interactive data exploration in neuroimaging: a simple example\n\n\n\n\n\n\n\nshiny app\n\n\nneuroimaging\n\n\n\n\n\n\n\n\n\n\n\nDec 28, 2022\n\n\nLC\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html",
    "href": "apps/dimred_app/dimred_app.html",
    "title": "Interactive data exploration in neuroimaging: a simple example",
    "section": "",
    "text": "Konrad Lorenz once said that “It is a good morning exercise for a research scientist to discard a pet hypothesis every day before breakfast. It keeps him young” (ref). Having spent quite some years doing scientific research, I can comfortably say that this is one of the mantra for the morning ritual of every researcher. Another useful mantra on the same line is a quote by Richard Feynman: “you must not fool yourself and you are the easiest person to fool” (ref).\nFrom a practical standpoint, these two quotes provide an interesting perspective on why I think visualization is so useful and actually indispensable for a researcher and for everyone who works with data: images are a great device to show us when our hypotheses are correct and when they are wrong (or when there is something wrong in the data).\nVisualization is key not just to communicate a complex result in an intuitive way, but also for inspecting every step of the analysis, in order to validate - or invalidate - previous assumptions, avoid wrong conclusions, get useful insights to re(de)fine our hypotheses, and design the next analytic step.\nAnother reason why data visualization is tremendously helpful in data analysis is that data is always multifaceted: when you look at it from different perspectives (e.g. different summary statistics, for different variables, observations, or groups of them), it shows one of its many aspect, and usually a meaningful result stands out only when there is consistency among most of the perspectives from which we can look at our data: only if it squeaks like a duck, looks like a duck, walks like a duck, then most likely it is… an interesting result. I find images great for this: being able to inspect at once different images showing different aspects of the data is very helpful to reveal consistencies and inconsistencies both in our data and in our hypotheses.\nInteractive visualization takes this ability one step forward. Now we can carry out some kind of transformation in one feature of our data - e.g. selecting different groups of variables - and see immediately the effect of this in other aspects of our data.\nIn neuroimaging - the field where I worked for most time - this can be particularly useful, since the variables associated with both data pre-processing and actual data analysis are so many, that it is of paramount importance to check as much as possible each step of the process. Even restricing our focus to the actual analysis, the complexity associated with our research questions can grow very quickly: are the data from my participants homogeneous? How do they compare between the different tasks presented in the experiment? Is the effect restricted to only specific regions? Or maybe is it more evident when looking at sets (and potentially networks) of brain regions?\nIn the following I will present a basic example of how different visualizations of the same data can help to inspect and gain insights on the results of a (fictitious) fMRI experiment. I hope to show that while exploring even a simple dataset, the complexity of questions that come to the mind grows very fast. This prompts us to go back to the code, modify it, create new code chunks in our notebook for intermediate checks, and so on. This process can become very complex and - frankly - very messy.\nAt this point, we might think about creating a device that allows us to look at all the different questions we have generated, and see how they affect the representation that we are creating in our mind about the data. Therefore, I will show an interactive version of it, where the different tables and plots we generated react when something is changed in one of them (e.g. selecting different brain regions).\nNot necessarily exploring data will prompt us to create an interactive app all the time, however its utility might become apparent for instance if we realize that such exploration steps might be useful for similar datasets in the future."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#a-simple-fmri-experiment",
    "href": "apps/dimred_app/dimred_app.html#a-simple-fmri-experiment",
    "title": "Interactive data exploration in neuroimaging: a simple example",
    "section": "A simple fMRI experiment",
    "text": "A simple fMRI experiment\nSuppose you want to compare brain activity during the execution of three different tasks: AAA, BBB and CCC. These tasks are behaviourally different, and your hypothesis is that this is reflected in which brain regions are recruited to perform each task. To test this hypothesis you set up an fMRI experiment where 30 participants execute many times each task while being in the scanner (this is an extremely simplified description of an fMRI experiment). The brain activity is recorded in each brain region, but for simplicity here we will focus only on nine of them.\nFor the purpose of showing the utility of our visual exploration of the data, we will generate fictitious data which is in accordance with the hypothesis. Specifically, I will generate summary statistics (mean activity) from 30 participants, showing that some brain regions are more active in task AAA and some in task CCC, while all examined brain regions do not appear to be particularly activated by task BBB.\n\n\nCode\nN = 30\n\nA <- function(mu) rnorm(N, mean = mu)\n\ndf <- tibble(\n task = c(rep(\"AAA\",N), rep(\"BBB\",N), rep(\"CCC\",N)) %>% as.factor(),\n  BA44  = c(A(2), A(2), A(5)),\n  BA45 = c(A(2), A(2), A(5)),\n  BA46  = c(A(2), A(3), A(5)),\n  V1  = c(A(2), A(2), A(2)),\n  V4  = c(A(2), A(2), A(2)),\n  V5  = c(A(2), A(2), A(2)),\n  SI   = c(A(5), A(2), A(2)),\n  SPL  = c(A(5), A(2), A(2)),\n  IPL  = c(A(5), A(3), A(2))\n) %>% \n group_by(task) %>%    # assign participant numbers\n # mutate(sub = paste0(\"sub_\",row_number())) %>%\n mutate(sub = paste0(\"sub_\",row_number(),\"_\",task)) %>%\n relocate(sub) %>%\n ungroup()\n \n\n# # plant an outlier\n# df[c(30,60,90),] %<>%  mutate(across(BA44:IPL, ~ .x + 4))\n\n# define a reusable function to print the table\nshow_table <- function(df) {\n \n BuYlRd <- function(x) {\n   rgb(colorRamp(c(\"#7fb7d7\", \"#ffffbf\", \"#fc8d59\"))(x), maxColorValue = 255)\n }\n \n  reactable(\n    df,\n   resizable = T,\n   # selection = \"multiple\",\n   # onClick = \"select\",\n   defaultColDef = colDef(\n     style = function(value) {\n        vals <- df %>% select(where(is.numeric))\n        if (!is.numeric(value)) return()\n        normalized <- (value - min(vals)) / (max(vals) - min(vals))\n        color <- BuYlRd(normalized)\n        list(background = color)\n      },\n     format = colFormat(digits = 2), minWidth = 50\n   ),\n   style = list(fontFamily = \"Arial narrow\", fontSize = \"13px\")\n  )\n}\n\ndf %>% show_table()\n\n\n\n\n\n\n\nThis is our complete dataset. It is very simplified (and clean) with respect to a real fMRI dataset, but it shows the many levels at which an fMRI can be examined:\n\nacross participants\nacross tasks\nacross brain regions\n\nand of course all the combinations of these levels. For instance we might be interested at the effect of a given task with respect to the other two in a specific brain region or in a specific set of brain regions.\nHere we start to see how quickly the complexity increases for the questions that we might ask even in a simple experiment like this. (It’s here that the interactive exploration will reveal its potential as we will see later).\nAlthough in this table I already color-coded brain the mean activity in each region for each task and each subject, it is quite difficult to have a clear view of the results."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#effect-of-task-in-different-brain-regions-across-participants",
    "href": "apps/dimred_app/dimred_app.html#effect-of-task-in-different-brain-regions-across-participants",
    "title": "Interactive data exploration in neuroimaging: a simple example",
    "section": "Effect of task in different brain regions across participants",
    "text": "Effect of task in different brain regions across participants\nAt this point we want to check whether the effect we hypothesize is consistent across participants. This is done to achieve a robust estimate of our effect of interest (and of its variability). One basic visualization of this mean result is in the form of a table:\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\n# df_mean %>% show_table()\n\n# pivot to group all the brain regions in a variable\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\n\nt_df_mean %>% show_table()\n\n\n\n\n\n\n\n\n\nNow the situation appears much more clear than when we looked at the data at the participant level, and indeed reflects how we actually generate the data: tasks CCC and AAA activate mostly the three top and bottom brain regions, respectively, while task BBB does not appear to activate any of the examined brain regions above baseline."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#a-different-visualization",
    "href": "apps/dimred_app/dimred_app.html#a-different-visualization",
    "title": "Interactive data exploration in neuroimaging: a simple example",
    "section": "A different visualization",
    "text": "A different visualization\nConsider however that here we are looking only at 9 brain regions, while in reality - in a whole-brain analysis - we look at least at 50+ regions (e.g. the 52 Brodmann areas). That is why I prefer to look at the same result with a graphical representation such as the following one.\nNB: in the following graph you can select specific tasks by clicking on the legend\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#reducing-the-dimensionality-for-a-sharper-view",
    "href": "apps/dimred_app/dimred_app.html#reducing-the-dimensionality-for-a-sharper-view",
    "title": "Interactive data exploration in neuroimaging: a simple example",
    "section": "Reducing the dimensionality for a sharper view",
    "text": "Reducing the dimensionality for a sharper view\nI find this visualization much easier to inspect than the table above. However, you might have noticed that we don’t know anymore what is going on at the level of the single participants. Of course are insights on the results so far are purely based on descriptive statistics, and appropriate inferential methods (e.g. ANOVA) will tell us whether the variability across tasks is substantially higher than that between participants. However, it can be useful to have a first look into this by looking at the main trajectories of variability across the entire initial dataset.\nLet’s see for instance what happens when we feed our initial participants-by-brain region table into UMAP.\n\n\nCode\ndo_dimred <- function(df, method, compX, compY, maxcomp=3) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = maxcomp)\n           pcs <- list(mds$points[,compX], mds$points[,compY])\n         },\n         umap = {\n           u <- umap(dist(vals), n_components = maxcomp)\n           pcs <- list(u[,compX], u[,compY])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 3, perplexity = 10)\n           pcs <- list(tsne$Y[,compX], tsne$Y[,compY])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\", compX = 1, compY = 2)\n\n\n\n\n\n\n\n\nHere each point represents one participant performing one task. The data is grouped in three clusters reflecting - not surprisingly - the difference in brain activity across all particiants and between tasks.\nInterestingly, we see that the brain activity for task BBB in one participant is grouped with a cluster which is mostly populated with activity for task AAA (hover on the orange dot in the green cloud). To inspect this potential anomaly, we can look into the initial data table and inspect the original values. Eventually we can go back to the original fMRI data and - through appropriate examination - decide if something went wrong with the data of this participant, e.g. during data acquisition or pre-processing.\nThis situation is made more clear if we artificially “plant” an anomaly in our data. I will not run this here, but you can download this RMarkdown notebook and run it on your computer. Check out how the UMAP is able to spot the “outliers” which were planted in the data.\n\n\nCode\n# plant an outlier\ngf <- df\ngf[c(29,30,59,60,89,90),] %<>%  mutate(across(BA44:IPL, ~ .x + 4))\n\ndo_dimred(gf,\"umap\", compX = 1, compY = 2)\n\ngf %>% show_table()"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#bringing-altogether-in-an-interactive-app",
    "href": "apps/dimred_app/dimred_app.html#bringing-altogether-in-an-interactive-app",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Bringing altogether in an interactive app",
    "text": "Bringing altogether in an interactive app\nWe have seen so far how many questions naturally arise even when looking at a intentionally very simplified dataset like the one we generated above.\nIf you read so far you have probably come up with a few other features that you would like to explore in one of the proposed visualization, and see how they affect the other perspectives from which we can look at the data.\nIt is probably clear by now that I am very intrigued by the possibility of exploration offered by dimensionality reduction methods such as UMAP. In the app which is displayed below, that you can open in full screen here, I implemented a few other possibilities that I encourage you to explore:\n\nFor instance, we might want to assess - for data exploration or based on a specific hypothesis - whether the expected effect would hold if you consider only a subset of the brain regions we looked at. This can be done by selecting the regions in the table, and observing the effect in the low-dimensional embedding.\nWe might also want to try to use other dimensionality reduction methoods besides UMAP (check for instance here). In the app, there is a choice of three different methods: Multi-dimensional Scaling (from the stats package), tSNE (from the Rtsne package) and UMAP (from the uwot package).\nAlso, to inspect the original values for each participant in each task, you just have to draw a lasso around the points you are interested in the low-dimensional embedding, and a heatmap of those values will appear in the lower-right corner of the app\n\nHopefully the potential usage of the app are self-explanatory, but if in doubt, check the animated gif at the beginning of this post."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#conclusion",
    "href": "apps/dimred_app/dimred_app.html#conclusion",
    "title": "Interactive data exploration in neuroimaging: a simple example",
    "section": "Conclusion",
    "text": "Conclusion\nThis post has already become much bigger than what I expected. I hope you found it useful or at least interesting, and I would be glad to know what you think about it by dropping me an email.\nI just want to offer two small considerations to conclude.\n\nBuilding an interactive app for data exploration/analysis is something that I dreamt about ever since I started to learn Matlab many years ago. Nowadays with the introduction of libraries such as Shiny for R (and recently also for Python), it has become a task that anyone with an interest in coding can get started with in a relatively short time, and that I personally find satisfying on many different levels. When you get a bit of experience, prototyping a basic app can take as short as one or a few days (as a matter of fact it took me way more time to write this post than the app)\nIn this example I looked only at the participant-level results. Instead in neuroimaging a large amount of time and code is spent on pre-processing the data and checking the results of the many steps involved therein - e.g. checking the outcome of registering one brain to a template, or the whole-brain temporal profile of an fMRI volume after bandpass filtering or de-noising. Although many neuroimaging suite already did a great job in implementing GUIs, you might want to look into other features which are not currently offered, or you might just want to implement an interface for the pre-processing pipelines you wrote. Having this in mind, I believe that libraries like Shiny bring a great potential for developing such personalized tools for researcher in neuroimaging."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "blog",
    "section": "",
    "text": "How to replace for loops using purrr::map\n\n\n\n\n\n\n\npurrr\n\n\n\n\n\n\n\n\n\n\n\nDec 26, 2022\n\n\nLC\n\n\n\n\n\n\n  \n\n\n\n\nIt is time to make a blog…\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDec 23, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#bringing-all-together-in-an-interactive-app",
    "href": "apps/dimred_app/dimred_app.html#bringing-all-together-in-an-interactive-app",
    "title": "Interactive data exploration in neuroimaging: a simple example",
    "section": "Bringing all together in an interactive app",
    "text": "Bringing all together in an interactive app\nWe have seen so far how many questions naturally arise even when looking at a intentionally very simplified dataset like the one we generated above.\nIf you read so far you have probably come up with a few other features that you would like to explore in one of the proposed visualization, and see how they affect the other perspectives from which we can look at the data.\nIt is probably clear by now that I am very intrigued by the possibility of exploration offered by dimensionality reduction methods such as UMAP. In the app which is displayed below, that you can open in full screen here, I implemented a few other possibilities that I encourage you to explore:\n\nFor instance, we might want to assess - for data exploration or based on a specific hypothesis - whether the expected effect would hold if you consider only a subset of the brain regions we looked at. This can be done by selecting the regions in the table, and observing the effect in the low-dimensional embedding.\nWe might also want to try to use other dimensionality reduction methoods besides UMAP (check for instance here). In the app, there is a choice of three different methods: Multi-dimensional Scaling (from the stats package), tSNE (from the Rtsne package) and UMAP (from the uwot package).\nAlso, to inspect the original values for each participant in each task, you just have to draw a lasso around the points you are interested in the low-dimensional embedding, and a heatmap of those values will appear in the lower-right corner of the app\n\nHopefully the potential usage of the app are self-explanatory, but if in doubt, check the animated gif at the beginning of this post."
  }
]