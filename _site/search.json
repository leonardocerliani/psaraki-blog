[
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html",
    "href": "posts/purrr_RManova/purrr_RManova.html",
    "title": "How to replace for loops using purrr::map",
    "section": "",
    "text": "In many cases you need to repeat the same action across multiple objects, for instance loading many files, or computing summary statistics across many vectors of observations. Instead of repeating the same operation manually for every object - which is not only time consuming, but especially prone to mistakes - you can use for loops.\nHowever for can be quite verbose, and especially in case you need to nest them - i.e. running a loop inside a loop - it can be difficult to inspect the code for errors during the analysis and especially in the future.\nBase R already provides some functions to avoid the creation of for loops, with the family of apply functions. However sometimes the syntax can be different across functions, and still a bit verbose.\nThe tidyverse provides functions that help getting rid of for loops for good using the purrr package. Below there is just an example. More details can be found in the iteration chapter of R for Data Science and in the functionals chapter of Advanced R\n\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(DT)\noptions(digits=2)\n\nLet’s say you collected data in 8 different runs of an experiment. For instance the time, in seconds, spent freezing, running or grooming in 10 participants after a given stimulus in each subsequent run.\nFor our example we will create some random data. The code below creates 8 dataframes with 10 observations for three distinct variables. It already uses the map function that we are going to explain later, so for now you can just disregard it, and come back later to understand what it does as an excercise.\n\n1:8 %>% map( function(x) {\n  tibble(\n    SUBID = map(1:10, ~ paste0(\"sub_\",.x) ) %>% unlist(),\n    freezing = runif(10)*10 * log(x+1),\n    running = runif(10)*10,\n    grooming = runif(10)*10\n  ) %>%\n    write_csv(paste0(\"run_\",x,\".csv\"))\n})\n\nWe obtain 8 csv files with our data.\n\nmyfiles <- list.files(pattern = \".csv\", full.names = T)\nmyfiles\n\n[1] \"./run_1.csv\" \"./run_2.csv\" \"./run_3.csv\" \"./run_4.csv\" \"./run_5.csv\"\n[6] \"./run_6.csv\" \"./run_7.csv\" \"./run_8.csv\"\n\nread.csv(\"run_1.csv\")\n\n    SUBID freezing running grooming\n1   sub_1     3.40   0.438      4.1\n2   sub_2     6.49   5.871      7.5\n3   sub_3     2.95   7.872      6.8\n4   sub_4     4.72   0.678      1.4\n5   sub_5     2.64   6.816      2.2\n6   sub_6     5.28   4.391      7.1\n7   sub_7     3.46   0.070      9.9\n8   sub_8     0.77   8.778      5.6\n9   sub_9     4.78   7.170      8.8\n10 sub_10     3.32   0.055      8.9"
  },
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html#purrrmap",
    "href": "posts/purrr_RManova/purrr_RManova.html#purrrmap",
    "title": "How to replace for loops using purrr::map",
    "section": "purrr::map",
    "text": "purrr::map\nNow you want to load everything in the same dataframe (i.e. table), for instance to carry out a RM-ANOVA. You could use a for loop to load all the files:\n\nallruns = vector(mode = \"list\", length = 8)\n\nfor (run in 1:length(allruns)) {\n  allruns[[run]] <- read.csv( myfiles[[run]] )\n}\n\n# allruns\n\nOr you could use the map function inside the purrr package\n\nallruns <- map(myfiles, read.csv)\n\n# allruns\n\nIn other words you passed to every element of the list myfiles the function read.csv\nNote the advantages:\n\nyou do not need to write extra code to initialize an empty list, since the result is automatically stored in a list\nyou don’t need to provide the total number of files,\nthe syntax is much more concise (and when you get used to it, also much more readable)."
  },
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html#purrrmap2",
    "href": "posts/purrr_RManova/purrr_RManova.html#purrrmap2",
    "title": "How to replace for loops using purrr::map",
    "section": "purrr::map2",
    "text": "purrr::map2\nTo carry out the RM-ANOVA, you need to combine all the tables into one singe dataframe, but also retain information about the different run.\nThe idea is the same as before: you have a function that creates a column with the run numba in each run’s data table. This means that you want to provide two lists: (1) the list containing the table of each run and (2) the list of filenames.\n\nalldata <- map2(allruns, myfiles, function(run, file) run %>% mutate(run = file)) %>% bind_rows()\n\nor with a more concise syntax:\n\nalldata <- map2_df(allruns, myfiles, ~ .x %>% mutate(run = .y))\n\nYou might have noticed that here I used a specific flavor of map, that is map_df, which returns a dataframe (or a tibble in the tidyverse language) instead of the default list, so that I can drop the final bind_rows()."
  },
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html#purrrpmap",
    "href": "posts/purrr_RManova/purrr_RManova.html#purrrpmap",
    "title": "How to replace for loops using purrr::map",
    "section": "purrr::pmap",
    "text": "purrr::pmap\nAs you might expect, there is also a function pmap which allows you to pass an arbitrary number of tables. I personally prefer this syntax since it allows me to pipe the list into it:\n\nalldata <- list(allruns, myfiles) %>% pmap_df(~ .x %>% mutate(run = .y))\n\n\ndatatable(alldata, options = list(dom = 'tp', scrollX = TRUE)) %>%\n  DT::formatRound(\n    columns = alldata %>% select(where(is.numeric)) %>% colnames(), \n    digits=2\n  )"
  },
  {
    "objectID": "posts/purrr_RManova/purrr_RManova.html#map-is-similar-to-group_by-for-dataframes",
    "href": "posts/purrr_RManova/purrr_RManova.html#map-is-similar-to-group_by-for-dataframes",
    "title": "How to replace for loops using purrr::map",
    "section": "map is similar to group_by for dataframes",
    "text": "map is similar to group_by for dataframes\nFinally, note that the map function - and its variation, such as pmap, is a similar operator for list to the group_by operator inside dataframes.\nFor instance let’s say that you want to get the mean and standard deviation for every variable in each run:\n\ndescriptives <- alldata %>% \n  group_by(run) %>%\n  summarise(\n    across(where(is.numeric), list(mean = mean, sd = sd)),\n    .groups = \"drop\"\n  ) %>% ungroup() \n\n\ndescriptives %>% \n  kbl() %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\n \n  \n    run \n    freezing_mean \n    freezing_sd \n    running_mean \n    running_sd \n    grooming_mean \n    grooming_sd \n  \n \n\n  \n    ./run_1.csv \n    3.8 \n    1.6 \n    4.2 \n    3.5 \n    6.2 \n    2.9 \n  \n  \n    ./run_2.csv \n    4.3 \n    2.5 \n    6.3 \n    2.4 \n    3.6 \n    2.1 \n  \n  \n    ./run_3.csv \n    7.0 \n    4.1 \n    4.8 \n    2.7 \n    6.4 \n    3.0 \n  \n  \n    ./run_4.csv \n    10.9 \n    3.3 \n    3.9 \n    2.7 \n    3.3 \n    2.2 \n  \n  \n    ./run_5.csv \n    8.7 \n    4.0 \n    4.9 \n    2.7 \n    4.4 \n    2.7 \n  \n  \n    ./run_6.csv \n    7.8 \n    5.0 \n    6.2 \n    2.1 \n    4.4 \n    2.2 \n  \n  \n    ./run_7.csv \n    9.7 \n    5.8 \n    3.7 \n    2.3 \n    6.4 \n    2.6 \n  \n  \n    ./run_8.csv \n    13.2 \n    5.9 \n    3.3 \n    2.8 \n    5.4 \n    3.4"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "It is time to make a blog…",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LC",
    "section": "",
    "text": "leonardo cerliani\nneuroimaging data analyst"
  },
  {
    "objectID": "apps.html",
    "href": "apps.html",
    "title": "Shiny apps",
    "section": "",
    "text": "Interactive exploration of neuroimaging results\n\n\n\n\n\n\n\nshiny app\n\n\nneuroimaging\n\n\n\n\n\n\n\n\n\n\n\nDec 28, 2022\n\n\nLC\n\n\n\n\n\n\n  \n\n\n\n\nDimred app OLE\n\n\n\n\n\n\n\nshiny app\n\n\nneuroimaging\n\n\n\n\nExploring multidimensional imaging results\n\n\n\n\n\n\nDec 22, 2022\n\n\nLC\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "apps/dimred_app/dimred_app_OLE.html",
    "href": "apps/dimred_app/dimred_app_OLE.html",
    "title": "Dimred app OLE",
    "section": "",
    "text": "Pippero\n\n\n\nThe app"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html",
    "href": "apps/dimred_app/dimred_app.html",
    "title": "Interactive exploration of neuroimaging results",
    "section": "",
    "text": "Konrad Lorenz once said that “It is a good morning exercise for a research scientist to discard a pet hypothesis every day before breakfast. It keeps him young” (ref). Having spent quite some years doing scientific research, I can comfortably say that this is one of the mantra for the morning ritual of every researcher. Another useful mantra on the same line is a quote by Richard Feynman: “you must not fool yourself and you are the easiest person to fool” (ref).\nFrom a practical standpoint, these two quotes provide an interesting perspective on why I think visualization is so useful and actually indispensable for a researcher and for everyone who works with data: images are a great device to show us when our hypotheses about the data we are working on are correct and when they are wrong (or when there is something wrong in the data).\nVisualization is key not just to communicate a complex result in an intuitive way, but also for inspecting every step of the analysis, in order to validate - or invalidate - previous assumptions, avoid wrong conclusions, get useful insights to re(de)fine our hypotheses, and design the next analytic step.\nAnother reason why data visualization is tremendously helpful in data analysis is that data is always multifaceted: when you look at it from different perspectives (e.g. different summary statistics, for different variables, observations, or groups of them), it shows one of its many aspect, and usually a meaningful result stands out only when there is consistency among most of the perspectives from which we can look at our data: only if it squeaks like a duck, looks like a duck, walks like a duck, then most likely it is… an interesting result. I find images great for this: being able to inspect at once different images showing different aspects of the data is very helpful to reveal consistencies and inconsistencies both in our data and in our hypotheses.\nInteractive visualization takes this ability one step forward. Now we can carry out some kind of transformation in one feature of our data - e.g. selecting different groups of variables - and see immediately the effect of this in other aspects of our data.\nIn neuroimaging - the field where I worked for most time - this can be particularly useful, since the variables associated with both data pre-processing and actual data analysis are so many, that it is of paramount importance to check as much as possible each step of the process. Even restricing our focus to the actual analysis, the complexity associated with our research questions can grow very quickly: are the data from my participants homogeneous? How do they compare between the different tasks presented in the experiment? Is the effect restricted to only specific regions? Or maybe is it more evident when looking at sets (and potentially networks) of brain regions?\nIn the following I will present a basic example of how different visualizations of the same data can help to inspect and gain insights on the results of a (fictitious) fMRI experiment. I hope to show that while exploring even a simple dataset, the complexity of questions that come to the mind grows very fast. This prompts us to go back to the code, modify it, create new code chunks in our notebook for intermediate checks, and so on. This process can become very complex and - frankly - very messy.\nAt this point, we might think about creating a device that allows us to look at all the different questions we have generated, and see how they affect the representation that we are creating in our mind about the data. Therefore, I will show an interactive version of it, where the different tables and plots we generated react when something is changed in one of them (e.g. selecting different brain regions).\nNot necessarily exploring data will prompt us to create an interactive app all the time, however its utility might become apparent for instance if we realize that such exploration steps might be useful for similar datasets in the future.\nYou can find the code for the static visualization in this post, while the code for the interactive version - a Shiny app - can be found in this github repo.\nCaveat: the data in this example are totally made up, they do not come from an actual experiement, since the aim is to show the potential of building such a tool. However, this machinery can be easily adapted to real data and personalized to the need of the investigator."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "blog",
    "section": "",
    "text": "How to replace for loops using purrr::map\n\n\n\n\n\n\n\npurrr\n\n\n\n\n\n\n\n\n\n\n\nDec 26, 2022\n\n\nLC\n\n\n\n\n\n\n  \n\n\n\n\nIt is time to make a blog…\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDec 23, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#look-at-the-data",
    "href": "apps/dimred_app/dimred_app.html#look-at-the-data",
    "title": "Interactive exploration of neuroimaging results",
    "section": "“Look at the data!”",
    "text": "“Look at the data!”\nAnscombe’s quartet perfectly exemplifies why during the long process of analysing a dataset it is important to continously carry out visual inspections of every step of the analysis: our summary statistics might have left out some important properties of the data that would produce unexpected, invalid or simply wrong results down the line.\nleonardo\n\n\n\n\nPrepare the data\n\n\nCode\nN = 30\n\nA <- function(mu) rnorm(N, mean = mu)\n\n\ndf <- tibble(\n task = c(rep(\"Execution\",N), rep(\"Motion\",N), rep(\"Scrambled\",N)) %>% as.factor(),\n GM_BA1  = c(A(2), A(2), A(5)),\n GM_BA44 = c(A(2), A(2), A(5)),\n GM_Ins  = c(A(2), A(3), A(5)),\n GM_SI   = c(A(5), A(2), A(2)),\n GM_SPL  = c(A(5), A(2), A(2)),\n GM_IPL  = c(A(5), A(3), A(2))\n)\n\ndf\n\n\n# A tibble: 90 × 7\n   task      GM_BA1 GM_BA44 GM_Ins GM_SI GM_SPL GM_IPL\n   <fct>      <dbl>   <dbl>  <dbl> <dbl>  <dbl>  <dbl>\n 1 Execution  1.55   2.19     2.79  5.94   4.42   5.52\n 2 Execution  1.01   1.41     2.68  4.53   5.81   4.48\n 3 Execution  2.51   2.83     3.20  4.10   4.55   6.91\n 4 Execution  3.21   3.00     2.38  2.80   5.29   5.60\n 5 Execution  1.89   2.95     1.27  6.99   4.82   6.50\n 6 Execution  0.561 -0.0629   3.16  6.71   5.89   5.08\n 7 Execution  1.58   0.927    3.26  6.15   4.65   3.54\n 8 Execution  4.13   1.76     1.45  6.55   5.71   5.06\n 9 Execution  1.82   1.06     3.63  4.27   4.60   5.12\n10 Execution  1.32   1.91     2.36  3.64   4.30   4.38\n# … with 80 more rows\n\n\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\ndf_mean\n\n\n# A tibble: 3 × 7\n  task      GM_BA1 GM_BA44 GM_Ins GM_SI GM_SPL GM_IPL\n  <fct>      <dbl>   <dbl>  <dbl> <dbl>  <dbl>  <dbl>\n1 Execution   2.08    1.71   2.10  5.13   4.88   5.40\n2 Motion      2.17    2.14   2.96  1.99   1.98   2.74\n3 Scrambled   5.23    4.88   4.95  1.89   1.93   1.91\n\n\n\n\nCode\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\nt_df_mean\n\n\n# A tibble: 6 × 4\n  JU      Execution Motion Scrambled\n  <chr>       <dbl>  <dbl>     <dbl>\n1 GM_BA1       2.08   2.17      5.23\n2 GM_BA44      1.71   2.14      4.88\n3 GM_Ins       2.10   2.96      4.95\n4 GM_SI        5.13   1.99      1.89\n5 GM_SPL       4.88   1.98      1.93\n6 GM_IPL       5.40   2.74      1.91\n\n\n\n\nCode\ndf_mean %>% t() %>% as_tibble()\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\n# A tibble: 7 × 3\n  V1        V2     V3       \n  <chr>     <chr>  <chr>    \n1 Execution Motion Scrambled\n2 2.1       2.2    5.2      \n3 1.7       2.1    4.9      \n4 2.1       3.0    4.9      \n5 5.1       2.0    1.9      \n6 4.9       2.0    1.9      \n7 5.4       2.7    1.9      \n\n\n\n\nCode\ndo_table <- function(t_df_mean) {\n  \n  BuYlRd <- function(x) rgb(colorRamp(c(\"#7fb7d7\", \"#ffffbf\", \"#fc8d59\"))(x), maxColorValue = 255)\n  \n  reactable(\n    t_df_mean, \n    resizable = T,\n    selection = \"multiple\", \n    onClick = \"select\",\n    defaultColDef = colDef(\n      style = function(value) {\n        vals <- t_df_mean %>% select(-JU)\n        if (!is.numeric(value)) return()\n        normalized <- (value - min(vals)) / (max(vals) - min(vals))\n        color <- BuYlRd(normalized)\n        list(background = color)\n      },\n      format = colFormat(digits = 2),\n      minWidth = 50\n    ),\n    style = list(fontFamily = \"Arial narrow\", fontSize = \"13px\")\n  )    \n}\n\ndo_table(t_df_mean)\n\n\n\n\n\n\n\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = 1:nsub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      # hoverinfo = 'text'\n      hovertemplate = paste('sub %{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\n\n\n\n\n\n\nCode\ndf %>%\n mutate(sub = paste0(\"sub_\",row_number())) %>% \n arrange(task) %>% \n column_to_rownames(var = \"sub\") %>%\n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#interactive-visualization-useful-or-just-fancy",
    "href": "apps/dimred_app/dimred_app.html#interactive-visualization-useful-or-just-fancy",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Interactive visualization: useful or just fancy?",
    "text": "Interactive visualization: useful or just fancy?\nVisualization is key in data analysis. Not just to communicate a complex result in an easy-to-grasp image, but also to inspect every step of the process in order to get insights about the further steps, and to limit the possibility of using invalid methods and draw wrong conclusions.\nIn the last years, tools to produce complex visual representations of data have become more and more accessible to everybody. This includes also tools that allow live interaction and therefore an active exploration of the data. However, IMHO these tools are meant to give a richer experience of the end product of the analysis, rather than being conceived as ways to explore different hypotheses while still in the middle of the data analytic process.\nI believe that this is particularly the case in academic research, both because the final product is usually meant to be something that eventually should be print on paper - i.e. a static image - and because there is still the perception that there is already too little time to come up with publishable results, let alone spending time in building tools for data exploration. Having worked for quite some time in Academia, I understand these issues, however I would like to offer some counter-arguments:\n\nScientific research requires testing many different hypotheses, mostly derived by some initial (wrong) hypotheses or assumptions. Building tools for interactive visualization of the data can speed up this process.\nPlatforms like Shiny (a library of R) have drastically decreased the time required to build a tool for interactive visualization/exploration of the data\nIn neuroimaging we usually look at what happens in each part (allow me the simplification) of the brain, usually in a summary statistics on a group of participants. Being able to quickly inspect what happens only in specific brain regions and in specific participants might give valuable insights to refine or revise our initial hypotheses towards unexpected interesting effects.\n\nIn the following I will show an example of how a quickly built Shiny app can allow inspecting the results of an fMRI analysis to derive useful insights about an experiment. I will not go into the details of the code (which you can find in this github repo). Instead I will explain the motivation under building it, and try to show why the interactive version is more useful than the static visualization of each step of the analysis.\n\n\n\nPrepare the data\n\n\nCode\nN = 30\n\nA <- function(mu) rnorm(N, mean = mu)\n\n\ndf <- tibble(\n task = c(rep(\"Execution\",N), rep(\"Motion\",N), rep(\"Scrambled\",N)) %>% as.factor(),\n GM_BA1  = c(A(2), A(2), A(5)),\n GM_BA44 = c(A(2), A(2), A(5)),\n GM_Ins  = c(A(2), A(3), A(5)),\n GM_SI   = c(A(5), A(2), A(2)),\n GM_SPL  = c(A(5), A(2), A(2)),\n GM_IPL  = c(A(5), A(3), A(2))\n)\n\ndf\n\n\n# A tibble: 90 × 7\n   task      GM_BA1 GM_BA44 GM_Ins GM_SI GM_SPL GM_IPL\n   <fct>      <dbl>   <dbl>  <dbl> <dbl>  <dbl>  <dbl>\n 1 Execution 1.08     0.128  2.74   6.11   5.35   4.86\n 2 Execution 1.37     1.24   0.978  5.99   2.03   4.86\n 3 Execution 1.47     1.94   2.95   3.86   4.33   5.42\n 4 Execution 2.43    -0.289  2.35   4.78   6.13   2.81\n 5 Execution 1.94     1.28   1.03   3.34   6.99   5.73\n 6 Execution 2.01     1.29   2.10   4.05   4.96   4.94\n 7 Execution 0.0775   1.16   1.70   4.14   4.45   6.85\n 8 Execution 3.54     0.498  2.28   4.29   6.62   5.41\n 9 Execution 2.36     2.97   0.611  6.52   2.97   6.21\n10 Execution 1.02     2.64   2.74   5.54   5.33   3.69\n# … with 80 more rows\n\n\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\ndf_mean\n\n\n# A tibble: 3 × 7\n  task      GM_BA1 GM_BA44 GM_Ins GM_SI GM_SPL GM_IPL\n  <fct>      <dbl>   <dbl>  <dbl> <dbl>  <dbl>  <dbl>\n1 Execution   1.86    1.82   2.01  5.05   4.78   5.27\n2 Motion      1.89    1.64   3.22  1.60   2.30   3.28\n3 Scrambled   5.09    5.13   5.18  1.82   2.18   1.96\n\n\n\n\nCode\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\nt_df_mean\n\n\n# A tibble: 6 × 4\n  JU      Execution Motion Scrambled\n  <chr>       <dbl>  <dbl>     <dbl>\n1 GM_BA1       1.86   1.89      5.09\n2 GM_BA44      1.82   1.64      5.13\n3 GM_Ins       2.01   3.22      5.18\n4 GM_SI        5.05   1.60      1.82\n5 GM_SPL       4.78   2.30      2.18\n6 GM_IPL       5.27   3.28      1.96\n\n\n\n\nCode\ndf_mean %>% t() %>% as_tibble()\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\n# A tibble: 7 × 3\n  V1        V2     V3       \n  <chr>     <chr>  <chr>    \n1 Execution Motion Scrambled\n2 1.9       1.9    5.1      \n3 1.8       1.6    5.1      \n4 2.0       3.2    5.2      \n5 5.0       1.6    1.8      \n6 4.8       2.3    2.2      \n7 5.3       3.3    2.0      \n\n\n\n\nCode\ndo_table <- function(t_df_mean) {\n  \n  BuYlRd <- function(x) rgb(colorRamp(c(\"#7fb7d7\", \"#ffffbf\", \"#fc8d59\"))(x), maxColorValue = 255)\n  \n  reactable(\n    t_df_mean, \n    resizable = T,\n    selection = \"multiple\", \n    onClick = \"select\",\n    defaultColDef = colDef(\n      style = function(value) {\n        vals <- t_df_mean %>% select(-JU)\n        if (!is.numeric(value)) return()\n        normalized <- (value - min(vals)) / (max(vals) - min(vals))\n        color <- BuYlRd(normalized)\n        list(background = color)\n      },\n      format = colFormat(digits = 2),\n      minWidth = 50\n    ),\n    style = list(fontFamily = \"Arial narrow\", fontSize = \"13px\")\n  )    \n}\n\ndo_table(t_df_mean)\n\n\n\n\n\n\n\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = 1:nsub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      # hoverinfo = 'text'\n      hovertemplate = paste('sub %{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\n\n\n\n\n\n\nCode\ndf %>%\n mutate(sub = paste0(\"sub_\",row_number())) %>% \n arrange(task) %>% \n column_to_rownames(var = \"sub\") %>%\n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#interactive-visualization-to-inspect-data-and-generaterefine-hypotheses",
    "href": "apps/dimred_app/dimred_app.html#interactive-visualization-to-inspect-data-and-generaterefine-hypotheses",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Interactive visualization to inspect data and generate/refine hypotheses",
    "text": "Interactive visualization to inspect data and generate/refine hypotheses\nVisualization is key in data analysis. Not just to communicate a complex result in an easy-to-grasp image, but also to inspect every step of the process in order to get insights about the further steps, and to limit the possibility of using invalid methods and draw wrong conclusions.\nIn the last years, tools to produce complex visual representations of data have become more and more accessible to everybody. This includes also tools that allow live interaction and therefore an active exploration of the data. However, IMHO these tools are meant to give a richer experience of the end product of the analysis, rather than being conceived as ways to explore different hypotheses while still in the middle of the data analytic process.\nI believe that this is particularly the case in academic research, both because the final product is usually meant to be something that eventually should be print on paper - i.e. a static image - and because there is still the perception that there is already too little time to come up with publishable results, let alone spending time in building tools for data exploration. Having worked for quite some time in Academia, I understand these issues, however I would like to offer some counter-arguments:\n\nScientific research requires testing many different hypotheses, mostly derived by some initial (wrong) hypotheses or assumptions. Building tools for interactive visualization of the data can speed up this process.\nPlatforms like Shiny (a library of R) have drastically decreased the time required to build a tool for interactive visualization/exploration of the data\nIn neuroimaging we usually look at what happens in each part (allow me the simplification) of the brain, usually in a summary statistics on a group of participants. Being able to quickly inspect what happens only in specific brain regions and in specific participants might give valuable insights to refine or revise our initial hypotheses towards unexpected interesting effects.\n\nIn the following I will show an example of how a quickly built Shiny app can allow inspecting the results of an fMRI analysis to derive useful insights about an experiment. I will not go into the details of the code (which you can find in this github repo). Instead I will explain the motivation under building it, and try to show why the interactive version is more useful than the static visualization of each step of the analysis.\n\n\n\nPrepare the data\n\n\nCode\nN = 30\n\nA <- function(mu) rnorm(N, mean = mu)\n\n\ndf <- tibble(\n task = c(rep(\"Execution\",N), rep(\"Motion\",N), rep(\"Scrambled\",N)) %>% as.factor(),\n GM_BA1  = c(A(2), A(2), A(5)),\n GM_BA44 = c(A(2), A(2), A(5)),\n GM_Ins  = c(A(2), A(3), A(5)),\n GM_SI   = c(A(5), A(2), A(2)),\n GM_SPL  = c(A(5), A(2), A(2)),\n GM_IPL  = c(A(5), A(3), A(2))\n)\n\ndf\n\n\n# A tibble: 90 × 7\n   task      GM_BA1 GM_BA44 GM_Ins GM_SI GM_SPL GM_IPL\n   <fct>      <dbl>   <dbl>  <dbl> <dbl>  <dbl>  <dbl>\n 1 Execution  1.48     2.52  0.809  5.58   5.26   5.52\n 2 Execution  4.42     2.36  2.49   5.25   5.23   4.54\n 3 Execution  0.239    2.18  2.63   3.20   4.97   2.82\n 4 Execution  3.04     2.22  2.64   3.15   3.90   6.39\n 5 Execution  1.61     3.35  1.54   4.79   5.34   5.85\n 6 Execution  3.44     2.49  1.58   6.49   5.08   5.31\n 7 Execution  0.793    1.13  1.38   5.25   4.50   5.44\n 8 Execution  3.08     1.99  1.72   4.89   4.72   5.86\n 9 Execution  2.14     1.05  2.76   4.11   5.92   5.89\n10 Execution  1.38     3.40  2.51   4.34   5.91   6.18\n# … with 80 more rows\n\n\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\ndf_mean\n\n\n# A tibble: 3 × 7\n  task      GM_BA1 GM_BA44 GM_Ins GM_SI GM_SPL GM_IPL\n  <fct>      <dbl>   <dbl>  <dbl> <dbl>  <dbl>  <dbl>\n1 Execution   1.92    2.02   1.77  5.09   4.67   5.09\n2 Motion      1.98    1.85   3.08  1.63   2.02   2.94\n3 Scrambled   5.16    5.00   5.13  1.63   1.99   2.43\n\n\n\n\nCode\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\nt_df_mean\n\n\n# A tibble: 6 × 4\n  JU      Execution Motion Scrambled\n  <chr>       <dbl>  <dbl>     <dbl>\n1 GM_BA1       1.92   1.98      5.16\n2 GM_BA44      2.02   1.85      5.00\n3 GM_Ins       1.77   3.08      5.13\n4 GM_SI        5.09   1.63      1.63\n5 GM_SPL       4.67   2.02      1.99\n6 GM_IPL       5.09   2.94      2.43\n\n\n\n\nCode\ndf_mean %>% t() %>% as_tibble()\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\n# A tibble: 7 × 3\n  V1        V2     V3       \n  <chr>     <chr>  <chr>    \n1 Execution Motion Scrambled\n2 1.9       2.0    5.2      \n3 2.0       1.9    5.0      \n4 1.8       3.1    5.1      \n5 5.1       1.6    1.6      \n6 4.7       2.0    2.0      \n7 5.1       2.9    2.4      \n\n\n\n\nCode\ndo_table <- function(t_df_mean) {\n  \n  BuYlRd <- function(x) rgb(colorRamp(c(\"#7fb7d7\", \"#ffffbf\", \"#fc8d59\"))(x), maxColorValue = 255)\n  \n  reactable(\n    t_df_mean, \n    resizable = T,\n    selection = \"multiple\", \n    onClick = \"select\",\n    defaultColDef = colDef(\n      style = function(value) {\n        vals <- t_df_mean %>% select(-JU)\n        if (!is.numeric(value)) return()\n        normalized <- (value - min(vals)) / (max(vals) - min(vals))\n        color <- BuYlRd(normalized)\n        list(background = color)\n      },\n      format = colFormat(digits = 2),\n      minWidth = 50\n    ),\n    style = list(fontFamily = \"Arial narrow\", fontSize = \"13px\")\n  )    \n}\n\ndo_table(t_df_mean)\n\n\n\n\n\n\n\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = 1:nsub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      # hoverinfo = 'text'\n      hovertemplate = paste('sub %{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\n\n\n\n\n\n\nCode\ndf %>%\n mutate(sub = paste0(\"sub_\",row_number())) %>% \n arrange(task) %>% \n column_to_rownames(var = \"sub\") %>%\n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#interactive-visualization-to-inspect-data-and-generate-or-refine-hypotheses",
    "href": "apps/dimred_app/dimred_app.html#interactive-visualization-to-inspect-data-and-generate-or-refine-hypotheses",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Interactive visualization to inspect data and generate or refine hypotheses",
    "text": "Interactive visualization to inspect data and generate or refine hypotheses\nVisualization is key in data analysis. Not just to communicate a complex result in an easy-to-grasp image, but also to inspect every step of the process in order to get insights about further steps, and to limit the possibility of using invalid methods and draw wrong conclusions.\nIn the last years, tools to produce complex visual representations of data have become more and more accessible to everybody. This includes also tools that allow live interaction and therefore active exploration of the data. However, IMHO these tools are meant to give a richer experience of the end product of the analysis, rather than being conceived as ways to explore different hypotheses while still in the middle of the data analytic process.\nI believe that this is particularly the case in academic research, both because the final product is usually meant to be something that eventually should be print on paper - i.e. a static image - and because there is still the perception that there is already too little time to come up with publishable results, let alone spending time in building tools for data exploration. Having worked for quite some time in Academia, I understand these issues, however I would like to offer some counter-arguments:\n\nScientific research requires testing many different hypotheses, mostly derived by some initial (possibly wrong) hypotheses or assumptions. Building tools for interactive visualization of the data can speed up this process.\nPlatforms like Shiny (a library of R) have drastically decreased the time required to build a tool for interactive visualization/exploration of the data - as I will try to convince you of below.\nIn neuroimaging we usually look at what happens in each part (allow me the simplification) of the brain, usually in a summary statistics on a group of participants. Being able to quickly inspect what happens only in specific brain regions and in specific participants might give valuable insights to refine or revise our initial hypotheses towards unexpected interesting effects.\n\nIn the following I will show an example of how a quickly built Shiny app can allow inspecting the results of an fMRI analysis to derive useful insights about an experiment. I will not go into the details of the code (which you can find in this github repo). Instead I will explain the motivation under building it, and try to show why the interactive version is more useful than the static visualization of each step of the analysis."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#a-classical-experiment",
    "href": "apps/dimred_app/dimred_app.html#a-classical-experiment",
    "title": "Interactive exploration of neuroimaging results",
    "section": "A classical experiment",
    "text": "A classical experiment\nSuppose you carry out an experiment where you want to compare which brain regions are more active in each of three different tasks: AAA, BBB, CCC. I will leave these tasks unnamed since the data is totally made up (although it can be easily adapted for a real-data situation). You record the activity in each brain region, but here we will focus only on six of them, named according to the (Brodmann atlas)[https://en.wikipedia.org/wiki/Brodmann_area].\nLet’s generate some data. Specifically, I will generate data from 30 participants, showing that some brain regions are more active in task AAA and some in task CCC, while these areas do not appear to be particularly activated by task BBB\n\n\nCode\nN = 30\n\nA <- function(mu) rnorm(N, mean = mu)\n\ndf <- tibble(\n task = c(rep(\"AAA\",N), rep(\"BBB\",N), rep(\"CCC\",N)) %>% as.factor(),\n GM_BA1  = c(A(2), A(2), A(5)),\n GM_BA44 = c(A(2), A(2), A(5)),\n GM_Ins  = c(A(2), A(3), A(5)),\n GM_SI   = c(A(5), A(2), A(2)),\n GM_SPL  = c(A(5), A(2), A(2)),\n GM_IPL  = c(A(5), A(3), A(2))\n)  %>% \n group_by(task) %>%\n mutate(sub = paste0(\"sub_\",row_number())) %>%\n relocate(sub) %>% \n ungroup()\n \n\nreactable(df,\n    resizable = T,\n    defaultColDef = colDef(\n      format = colFormat(digits = 2),\n      minWidth = 50\n    ),\n    style = list(fontFamily = \"Arial narrow\")\n)\n\n\n\n\n\n\n\nCode\n# df %>%\n#  group_by(task) %>% \n#  mutate(sub = paste0(\"sub_\",row_number())) %>% \n#  relocate(sub)\n\n\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\ndf_mean\n\n\n# A tibble: 3 × 7\n  task  GM_BA1 GM_BA44 GM_Ins GM_SI GM_SPL GM_IPL\n  <fct>  <dbl>   <dbl>  <dbl> <dbl>  <dbl>  <dbl>\n1 AAA     2.26    2.04   2.09  4.95   5.19   4.95\n2 BBB     1.63    2.21   2.59  1.98   1.81   2.91\n3 CCC     4.82    5.20   5.09  2.06   2.16   1.81\n\n\n\n\nCode\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\nt_df_mean\n\n\n# A tibble: 6 × 4\n  JU        AAA   BBB   CCC\n  <chr>   <dbl> <dbl> <dbl>\n1 GM_BA1   2.26  1.63  4.82\n2 GM_BA44  2.04  2.21  5.20\n3 GM_Ins   2.09  2.59  5.09\n4 GM_SI    4.95  1.98  2.06\n5 GM_SPL   5.19  1.81  2.16\n6 GM_IPL   4.95  2.91  1.81\n\n\n\n\nCode\ndo_table <- function(t_df_mean) {\n  \n  BuYlRd <- function(x) rgb(colorRamp(c(\"#7fb7d7\", \"#ffffbf\", \"#fc8d59\"))(x), maxColorValue = 255)\n  \n  reactable(\n    t_df_mean, \n    resizable = T,\n    selection = \"multiple\", \n    onClick = \"select\",\n    defaultColDef = colDef(\n      style = function(value) {\n        vals <- t_df_mean %>% select(-JU)\n        if (!is.numeric(value)) return()\n        normalized <- (value - min(vals)) / (max(vals) - min(vals))\n        color <- BuYlRd(normalized)\n        list(background = color)\n      },\n      format = colFormat(digits = 2),\n      minWidth = 50\n    ),\n    style = list(fontFamily = \"Arial narrow\", fontSize = \"13px\")\n  )    \n}\n\ndo_table(t_df_mean)\n\n\n\n\n\n\n\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = 1:nsub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      # hoverinfo = 'text'\n      hovertemplate = paste('sub %{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\nWarning in dist(vals): NAs introduced by coercion\n\n\n\n\n\n\n\n\nCode\ndf %>%\n mutate(sub = paste0(\"sub_\",row_number())) %>% \n arrange(task) %>% \n column_to_rownames(var = \"sub\") %>%\n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#a-classic-experiment",
    "href": "apps/dimred_app/dimred_app.html#a-classic-experiment",
    "title": "Interactive exploration of neuroimaging results",
    "section": "A classic experiment",
    "text": "A classic experiment\nSuppose you carry out an experiment where you want to compare which brain regions are more active in each of three different tasks: AAA, BBB, CCC. I will leave these tasks unnamed since the data is totally made up (although it can be easily adapted for a real-data situation). You record the activity in each brain region, but here we will focus only on six of them, named according to the Brodmann atlas.\nLet’s generate some data. Specifically, I will generate data from 30 participants, showing that some brain regions are more active in task AAA and some in task CCC, while these areas do not appear to be particularly activated by task BBB\n\n\nCode\nN = 30\n\nA <- function(mu) rnorm(N, mean = mu)\n\ndf <- tibble(\n task = c(rep(\"AAA\",N), rep(\"BBB\",N), rep(\"CCC\",N)) %>% as.factor(),\n GM_BA1  = c(A(2), A(2), A(5)),\n GM_BA44 = c(A(2), A(2), A(5)),\n GM_Ins  = c(A(2), A(3), A(5)),\n GM_SI   = c(A(5), A(2), A(2)),\n GM_SPL  = c(A(5), A(2), A(2)),\n GM_IPL  = c(A(5), A(3), A(2))\n) %>% \n group_by(task) %>%\n mutate(sub = paste0(\"sub_\",row_number())) %>%\n relocate(sub) %>%\n ungroup()\n \n\nreactable(df,\n    resizable = T,\n    defaultColDef = colDef(\n      format = colFormat(digits = 2),\n      minWidth = 50\n    ),\n    style = list(fontFamily = \"Arial narrow\")\n)\n\n\n\n\n\n\n\nCode\n# df %>%\n#  group_by(task) %>% \n#  mutate(sub = paste0(\"sub_\",row_number())) %>% \n#  relocate(sub)\n\n\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\ndf_mean\n\n\n# A tibble: 3 × 7\n  task  GM_BA1 GM_BA44 GM_Ins GM_SI GM_SPL GM_IPL\n  <fct>  <dbl>   <dbl>  <dbl> <dbl>  <dbl>  <dbl>\n1 AAA     2.20    2.17   1.99  5.10   5.44   4.82\n2 BBB     1.54    2.26   2.99  2.04   1.88   3.14\n3 CCC     5.09    5.12   4.97  1.93   2.23   2.07\n\n\n\n\nCode\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\nt_df_mean\n\n\n# A tibble: 6 × 4\n  JU        AAA   BBB   CCC\n  <chr>   <dbl> <dbl> <dbl>\n1 GM_BA1   2.20  1.54  5.09\n2 GM_BA44  2.17  2.26  5.12\n3 GM_Ins   1.99  2.99  4.97\n4 GM_SI    5.10  2.04  1.93\n5 GM_SPL   5.44  1.88  2.23\n6 GM_IPL   4.82  3.14  2.07\n\n\n\n\nCode\ndo_table <- function(t_df_mean) {\n  \n  BuYlRd <- function(x) rgb(colorRamp(c(\"#7fb7d7\", \"#ffffbf\", \"#fc8d59\"))(x), maxColorValue = 255)\n  \n  reactable(\n    t_df_mean, \n    resizable = T,\n    selection = \"multiple\", \n    onClick = \"select\",\n    defaultColDef = colDef(\n      style = function(value) {\n        vals <- t_df_mean %>% select(-JU)\n        if (!is.numeric(value)) return()\n        normalized <- (value - min(vals)) / (max(vals) - min(vals))\n        color <- BuYlRd(normalized)\n        list(background = color)\n      },\n      format = colFormat(digits = 2),\n      minWidth = 50\n    ),\n    style = list(fontFamily = \"Arial narrow\", fontSize = \"13px\")\n  )    \n}\n\ndo_table(t_df_mean)\n\n\n\n\n\n\n\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\nWarning in dist(vals): NAs introduced by coercion\n\n\n\n\n\n\n\n\nCode\ndf %>% head() %>%\n arrange(task) %>% \n column_to_rownames(var = \"sub\") %>% \n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#interactive-visualization-to-redefine-hypotheses",
    "href": "apps/dimred_app/dimred_app.html#interactive-visualization-to-redefine-hypotheses",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Interactive visualization to re(de)fine hypotheses",
    "text": "Interactive visualization to re(de)fine hypotheses\nVisualization is key in data analysis. Not just to communicate a complex result in an easy-to-grasp image, but also to inspect every step of the process in order to get insights about further steps, and to limit the possibility of using invalid methods and draw wrong conclusions.\nIn the last years, tools to produce complex visual representations of data have become more and more accessible to everybody. This includes also tools that allow live interaction and therefore active exploration of the data. However, generally these tools are meant to give a richer experience of the end product of the analysis, rather than being conceived as ways to explore different hypotheses while still in the middle of the data analytic process.\nI believe that this is particularly the case in academic research, both because the final product is usually meant to be something that eventually should be print on paper - i.e. a static image - and because there is still the perception that there is already too little time to come up with publishable results, let alone spending time in building tools for data exploration. Having worked for quite some time in Academia, I understand these issues, however I would like to offer some counter-arguments:\n\nScientific research requires testing many different hypotheses, mostly derived by some initial (possibly wrong) hypotheses or assumptions. Building tools for interactive visualization of the data can speed up this process.\nPlatforms like Shiny (a library of R) have drastically decreased the time required to build a tool for interactive visualization/exploration of the data - as I will try to convince you of below.\nIn neuroimaging we usually look at what happens in each part (allow me the simplification) of the brain, usually in a summary statistics on a group of participants. Being able to quickly inspect what happens only in specific brain regions and in specific participants might give valuable insights to refine or revise our initial hypotheses towards unexpected interesting effects.\n\nIn the following I will show an example of how a quickly built Shiny app can allow inspecting the results of an fMRI analysis to derive useful insights about an experiment. I will not go into the details of the code (which you can find in this github repo). Instead I will explain the motivation under building it, and try to show why the interactive version is more useful than the static visualization of each step of the analysis."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#a-simple-experiment",
    "href": "apps/dimred_app/dimred_app.html#a-simple-experiment",
    "title": "Interactive exploration of neuroimaging results",
    "section": "A simple experiment",
    "text": "A simple experiment\nSuppose you carry out an fMRI experiment where you want to compare which brain regions are more active in each of three different tasks: AAA, BBB, CCC. Each participant is presented with all the tasks. The brain activity is recorded in each brain region, but for simplicity here we will focus only on six of them, named according to the Brodmann atlas.\nLet’s generate some data. Specifically, I will generate summary statistics (mean activity) from 30 participants, showing that some brain regions are more active in task AAA and some in task CCC, while these areas do not appear to be particularly activated by task BBB\n\n\nCode\nN = 30\n\nA <- function(mu) rnorm(N, mean = mu)\n\ndf <- tibble(\n task = c(rep(\"AAA\",N), rep(\"BBB\",N), rep(\"CCC\",N)) %>% as.factor(),\n  BA44  = c(A(2), A(2), A(5)),\n  BA45 = c(A(2), A(2), A(5)),\n  BA46  = c(A(2), A(3), A(5)),\n  V1  = c(A(2), A(2), A(2)),\n  V4  = c(A(2), A(2), A(2)),\n  V5  = c(A(2), A(2), A(2)),\n  SI   = c(A(5), A(2), A(2)),\n  SPL  = c(A(5), A(2), A(2)),\n  IPL  = c(A(5), A(3), A(2))\n) %>% \n group_by(task) %>%    # assign participant numbers\n mutate(sub = paste0(\"sub_\",row_number())) %>%\n relocate(sub) %>%\n ungroup()\n \n\n# define a reusable function to print the table\nshow_table <- function(df) {\n \n BuYlRd <- function(x) {\n   rgb(colorRamp(c(\"#7fb7d7\", \"#ffffbf\", \"#fc8d59\"))(x), maxColorValue = 255)\n }\n \n  reactable(\n    df,\n   resizable = T,\n   # selection = \"multiple\",\n   # onClick = \"select\",\n   defaultColDef = colDef(\n     style = function(value) {\n        vals <- df %>% select(where(is.numeric))\n        if (!is.numeric(value)) return()\n        normalized <- (value - min(vals)) / (max(vals) - min(vals))\n        color <- BuYlRd(normalized)\n        list(background = color)\n      },\n     format = colFormat(digits = 2), minWidth = 50\n   ),\n   style = list(fontFamily = \"Arial narrow\", fontSize = \"13px\")\n  )\n}\n\ndf %>% show_table()\n\n\n\n\n\n\n\nThis is our complete dataset. It is very simplified (and clean) with respect to a real fMRI dataset, but it shows the many levels at which an fMRI can be examined:\n\nacross participants\nacross tasks\nacross brain regions\n\nand of course all the combinations of these levels. For instance we might be interested at the effect of a given task with respect to the other two in a specific brain region or in a specific set of brain regions.\nHere we start to see how quickly the complexity increases for the questions that we might ask even in a simple experiment like this. It’s here that the interactive exploration will reveal its potential (as we will see later)."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#the-utility-of-interactive-visualization-in-neuroimaging",
    "href": "apps/dimred_app/dimred_app.html#the-utility-of-interactive-visualization-in-neuroimaging",
    "title": "Interactive exploration of neuroimaging results",
    "section": "The utility of interactive visualization in neuroimaging",
    "text": "The utility of interactive visualization in neuroimaging\nVisualization is key in data analysis. Not just to communicate a complex result in an easy-to-grasp image, but also to inspect every step of the process in order to get insights about further steps, re(de)fine experimental hypotheses, and to limit the possibility of using invalid methods that would lead to wrong conclusions.\nIn the last years, tools to produce complex visual representations of data have become progressively more accessible to everybody. This includes also tools that allow live interaction and therefore active exploration of the data. However, generally these tools are meant to give a richer experience of the end product of the analysis, rather than being conceived as ways to explore different hypotheses while still in the middle of the data analytic process.\nI believe that this is particularly the case in academic research, both because the final product is usually meant to be something that eventually should be print on paper - i.e. a static image - and because there is still the perception that there is already too little time to come up with publishable results, let alone spending time in building tools for data exploration. Having worked for quite some time in Academia, I understand these issues, however I would like to offer some counter-arguments:\n\nScientific research requires testing many different hypotheses, mostly derived by some initial (possibly wrong) hypotheses or assumptions. Building tools for interactive visualization of the data can speed up this process.\nPlatforms like Shiny (a library of R) have drastically decreased the time required to build a tool for interactive visualization/exploration of the data - as I will try to convince you of below.\nIn neuroimaging we usually look at what happens in each part (allow me the simplification) of the brain, usually in a summary statistics on a group of participants. Being able to quickly inspect what happens only in specific brain regions and in specific participants might give valuable insights to refine or revise our initial hypotheses towards unexpected interesting effects.\n\nIn the following I will show an example of how a quickly built Shiny app can allow inspecting the results of an fMRI analysis to derive useful insights about an experiment. I will not go into the details of the code (which you can find in this github repo). Instead I will explain the motivation under building it, and try to show why the interactive version is more useful than the static visualization of each step of the analysis."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#the-utility-of-interactive-visualization-in-scientific-research",
    "href": "apps/dimred_app/dimred_app.html#the-utility-of-interactive-visualization-in-scientific-research",
    "title": "Interactive exploration of neuroimaging results",
    "section": "The utility of interactive visualization in scientific research",
    "text": "The utility of interactive visualization in scientific research\nVisualization is key in data analysis. Not just to communicate a complex result in an easy-to-grasp image, but also to inspect every step of the process in order to get insights about further steps, re(de)fine experimental hypotheses, and to limit the possibility of using invalid methods that would lead to wrong conclusions.\nIn the last years, tools to produce complex visual representations of data have become progressively more accessible to everybody. This includes also tools that allow live interaction and therefore active exploration of the data. However, generally these tools are meant to give a richer experience of the end product of the analysis, rather than being conceived as ways to explore different hypotheses while still in the middle of the data analytic process.\nI believe that this is particularly the case in academic research, both because the final product is usually meant to be something that eventually should be print on paper - i.e. a static image - and because there is still the perception that there is already too little time to come up with publishable results, let alone spending time in building tools for data exploration. Having worked for quite some time in Academia, I understand these issues, however I would like to offer some counter-arguments:\n\n\nScientific research requires testing many different hypotheses, mostly derived by some initial (possibly wrong) hypotheses or assumptions. Building tools for interactive visualization of the data can speed up this process.\nSpecifically in neuroimaging we usually look at what happens in each part (allow me the simplification) of the brain, usually in a summary statistics on a group of participants. Being able to quickly inspect what happens only in specific brain regions and in specific participants might give valuable insights to refine or revise our initial hypotheses due to unexpected interesting effects.\nPlatforms like Shiny (a library of R) have drastically decreased the time required to build a tool for interactive visualization/exploration of the data - as I will try to convince you of below.\n\nIn the following I will show an example of how a quickly built Shiny app can allow inspecting the results of an fMRI analysis to derive useful insights about an experiment.\nI will present different visualizations for the same results, and then link them with each other, so that modifying the choice on one visualization would affect the others. I hope to convince you that such an interactive environment can generate useful insights about the results, and can be built quite quickly. I will not go into the details of the code (which you can find in this github repo).\nCaveat: the data in this example are totally made up, they do not represent actual neuroimaging data, since the aim is to show the potential of building such a tool. However, this machinery can be easily adapted to real data and personalized to the need of the investigator."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#utility-of-interactive-visualization-in-scientific-research",
    "href": "apps/dimred_app/dimred_app.html#utility-of-interactive-visualization-in-scientific-research",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Utility of interactive visualization in scientific research",
    "text": "Utility of interactive visualization in scientific research\nVisualization is key in data analysis. Not just to communicate a complex result in an intuitive way, but also for inspecting every step of the analysis, in order to validate previous assumptions and get insights useful to design the next step.\nIn the last years, tools for generating complex visual representations of data have become progressively more accessible. These includes also libraries for live interaction and therefore active exploration of the data. However, generally these tools are meant to give a richer experience of the end product of the analysis, rather than being conceived as ways to explore different hypotheses while still in the middle of the data analysis.\nI believe that this is particularly the case in academic research, both because the final product is usually meant to be something that eventually should be print on paper - i.e. a static image - and because there is still the perception that there is already too little time to come up with publishable results, let alone spending time in building tools for data exploration. Having worked for quite some time in Academia, I understand these issues, however I would like to offer some counter-arguments:\n\nScientific research requires testing many different hypotheses, mostly derived by some initial (possibly wrong) hypotheses or assumptions. Building tools for interactive visualization of the data can speed up this process.\nSpecifically in neuroimaging we usually look at what happens in each part (allow me the simplification) of the brain, usually in a summary statistics on a group of participants. Being able to quickly inspect what happens only in specific brain regions and in specific participants might give valuable insights to refine or revise our initial hypotheses due to unexpected interesting effects.\nPlatforms like Shiny (a library of R) have drastically decreased the time required to build a tool for interactive visualization/exploration of the data - as I will try to convince you of below.\n\nIn the following I will show an example of how a quickly built Shiny app can allow inspecting the results of an fMRI analysis to derive useful insights about an experiment.\nI will present different visualizations for the same results, and then link them with each other, so that modifying the choice on one visualization would affect the others. I hope to convince you that such an interactive environment can generate useful insights about the results, and can be built quite quickly. I will not go into the details of the code (which you can find in this github repo).\nCaveat: the data in this example are totally made up, they do not come from an actual experiement, since the aim is to show the potential of building such a tool. However, this machinery can be easily adapted to real data and personalized to the need of the investigator."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#mean-activity-across-brain-regions-and-across-tasks",
    "href": "apps/dimred_app/dimred_app.html#mean-activity-across-brain-regions-and-across-tasks",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Mean activity across brain regions and across tasks",
    "text": "Mean activity across brain regions and across tasks\nExcept for specific situations, when we conduct such experiment we are interested to see what happens on average across all participants. This is done to achieve a robust estimate of our effect of interest (and of its variability). One basic visualization of this mean result is in the form of a table:\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\n# df_mean %>% show_table()\n\n# pivot to group all the brain regions in a variable\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\n\nt_df_mean %>% show_table()\n\n\n\n\n\n\n\n\n\nThis visualization shows our main result - which reflects how we actually generate the data: tasks CCC and AAA activate mostly the three top and bottom brain regions, respectively, while task BBB does not appear to activate any of the observed brain regions above baseline.\nConsider that this dataset is very clean, and we are looking only at 6 brain regions, while in reality - in a whole-brain analysis - we look at least at 50+ regions. That is why I prefer to look at the same result with a graphical representation such as the following one.\nNB: in the following graph you can select specific tasks by clicking on the legend\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nI find this visualization much easier to inspect than the table above. However, in some cases it might not be as intuitive - for instance, the differences between the activity in different tasks might not be as strong, and might not be featured in brain regions that (we decided) to plot as close to each other on the circle.\nIn general,\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\n\n\n\n\n\n\nCode\ndf %>% head() %>%\n arrange(task) %>% \n column_to_rownames(var = \"sub\") %>% \n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#mean-activity-across-regions-and-tasks",
    "href": "apps/dimred_app/dimred_app.html#mean-activity-across-regions-and-tasks",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Mean activity across regions and tasks",
    "text": "Mean activity across regions and tasks\nExcept for specific situations, when we conduct such experiment we are interested to see what happens on average across all participants. This is done to achieve a robust estimate of our effect of interest (and of its variability). One basic visualization of this mean result is in the form of a table:\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\n# df_mean %>% show_table()\n\n# pivot to group all the brain regions in a variable\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\n\nt_df_mean %>% show_table()\n\n\n\n\n\n\n\n\n\nThis visualization shows our main result - which reflects how we actually generate the data: tasks CCC and AAA activate mostly the three top and bottom brain regions, respectively, while task BBB does not appear to activate any of the observed brain regions above baseline.\nConsider that this dataset is very clean, and we are looking only at 6 brain regions, while in reality - in a whole-brain analysis - we look at least at 50+ regions. That is why I prefer to look at the same result with a graphical representation such as the following one.\nNB: in the following graph you can select specific tasks by clicking on the legend\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nI find this visualization much easier to inspect than the table above. However, in some cases it might not be as intuitive - for instance, the differences between the activity in different tasks might not be as strong, and might not be featured in brain regions that (we decided) to plot as close to each other on the circle.\nIn general,\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\n\n\n\n\n\n\nCode\ndf %>% head() %>%\n arrange(task) %>% \n column_to_rownames(var = \"sub\") %>% \n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#mean-activity-across-tasks",
    "href": "apps/dimred_app/dimred_app.html#mean-activity-across-tasks",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Mean activity across tasks",
    "text": "Mean activity across tasks\nExcept for specific situations, when we conduct such experiment we are interested to see what happens on average across all participants. This is done to achieve a robust estimate of our effect of interest (and of its variability). One basic visualization of this mean result is in the form of a table:\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\n# df_mean %>% show_table()\n\n# pivot to group all the brain regions in a variable\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\n\nt_df_mean %>% show_table()\n\n\n\n\n\n\n\n\n\nThis visualization shows our main result - which reflects how we actually generate the data: tasks CCC and AAA activate mostly the three top and bottom brain regions, respectively, while task BBB does not appear to activate any of the observed brain regions above baseline.\nConsider that this dataset is very clean, and we are looking only at 6 brain regions, while in reality - in a whole-brain analysis - we look at least at 50+ regions. That is why I prefer to look at the same result with a graphical representation such as the following one.\nNB: in the following graph you can select specific tasks by clicking on the legend\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nI find this visualization much easier to inspect than the table above. However, in some cases it might not be as intuitive - for instance, the differences between the activity in different tasks might not be as strong, and might not be featured in brain regions that (we decided) to plot as close to each other on the circle.\nIn general,\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\n\n\n\n\n\n\nCode\ndf %>% head() %>%\n arrange(task) %>% \n column_to_rownames(var = \"sub\") %>% \n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#mean-activity-for-each-tasks",
    "href": "apps/dimred_app/dimred_app.html#mean-activity-for-each-tasks",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Mean activity for each tasks",
    "text": "Mean activity for each tasks\nExcept for specific situations, when we conduct such experiment we are interested to see what happens on average across all participants. This is done to achieve a robust estimate of our effect of interest (and of its variability). One basic visualization of this mean result is in the form of a table:\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\n# df_mean %>% show_table()\n\n# pivot to group all the brain regions in a variable\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\n\nt_df_mean %>% show_table()\n\n\n\n\n\n\n\n\n\nThis visualization shows our main result - which reflects how we actually generate the data: tasks CCC and AAA activate mostly the three top and bottom brain regions, respectively, while task BBB does not appear to activate any of the observed brain regions above baseline.\nConsider that this dataset is very clean, and we are looking only at 6 brain regions, while in reality - in a whole-brain analysis - we look at least at 50+ regions. That is why I prefer to look at the same result with a graphical representation such as the following one.\nNB: in the following graph you can select specific tasks by clicking on the legend\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nI find this visualization much easier to inspect than the table above. However, in some cases it might not be as intuitive - for instance, the differences between the activity in different tasks might not be as strong, and might not be featured in brain regions that (we decided) to plot as close to each other on the circle.\nIn general,\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\n\n\n\n\n\n\nCode\ndf %>% head() %>%\n arrange(task) %>% \n column_to_rownames(var = \"sub\") %>% \n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#effect-of-task-in-different-brain-regions",
    "href": "apps/dimred_app/dimred_app.html#effect-of-task-in-different-brain-regions",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Effect of task in different brain regions",
    "text": "Effect of task in different brain regions\nExcept for specific situations, when we conduct such experiment we are interested to see what happens on average across all participants. This is done to achieve a robust estimate of our effect of interest (and of its variability). One basic visualization of this mean result is in the form of a table:\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\n# df_mean %>% show_table()\n\n# pivot to group all the brain regions in a variable\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\n\nt_df_mean %>% show_table()"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#another-perspective-on-the-same-results",
    "href": "apps/dimred_app/dimred_app.html#another-perspective-on-the-same-results",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Another perspective on the same results",
    "text": "Another perspective on the same results\nThis visualization shows our main result - which reflects how we actually generate the data: tasks CCC and AAA activate mostly the three top and bottom brain regions, respectively, while task BBB does not appear to activate any of the observed brain regions above baseline.\nConsider that this dataset is very clean, and we are looking only at 6 brain regions, while in reality - in a whole-brain analysis - we look at least at 50+ regions. That is why I prefer to look at the same result with a graphical representation such as the following one.\nNB: in the following graph you can select specific tasks by clicking on the legend\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nI find this visualization much easier to inspect than the table above. However, in some cases it might not be as intuitive - for instance, the differences between the activity in different tasks might not be as strong, and might not be featured in brain regions that (we decided) to plot as close to each other on the circle.\nIn general, when executing a task, a network of brain regions is recruited - or to be cautious, a set of brain regions that we assume are working together for that task. One interesting question to ask is therefore whether different tasks recruit different sets of brain regions. This is a typical question that can be investigated with a dimensionality reduction technique (e.g. clustering).\nLet’s see for instance what happens when we feed the previous results into UMAP.\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\n\n\n\n\n\n\nThis plot clearly shows that the three tasks recruit different (sub)sets of the originally investigated brain regions. IMHO, this is the clearest representation of our hypotheses - or to be more precise, in this case, of how we constructed our dataset.\nNote however that this plot does not tell us which regions are in the (sub)set recruited by each task. For that, the previous plot can help, and maybe even the initial table, if we were able to select only specific brain regions for our plot and our dimensionality reduction estimation. The latter is something that is implemented in the interactive version below.\nOne last - important - thing that this UMAP plot shows is that the clusters are not completely homogeneous: some participants’s activity for a given task appears in the cluster of a different task. This can be due to many reasons, and it would be nice to investigate why.\nWe can investigate brain activity at the participant level using for instance a simple heatmap like the one below.\n\n\nCode\ndf %>% head(15) %>% \n arrange(task) %>%\n mutate(sub = paste(sub,task,sep = '_')) %>%\n column_to_rownames(var = \"sub\") %>% \n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))\n\n\n\n\n\n\nThis would be particularly useful if we could select all the participants in each cluster using a lasso. This is exactly what is implemented in the interactive version below."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#another-view-on-the-same-results",
    "href": "apps/dimred_app/dimred_app.html#another-view-on-the-same-results",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Another view on the same results",
    "text": "Another view on the same results\nThis visualization shows our main result - which reflects how we actually generate the data: tasks CCC and AAA activate mostly the three top and bottom brain regions, respectively, while task BBB does not appear to activate any of the observed brain regions above baseline.\nConsider that this dataset is very clean, and we are looking only at 6 brain regions, while in reality - in a whole-brain analysis - we look at least at 50+ regions. That is why I prefer to look at the same result with a graphical representation such as the following one.\nNB: in the following graph you can select specific tasks by clicking on the legend\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)\n\n\n\n\n\n\n\n\nI find this visualization much easier to inspect than the table above. However, in some cases it might not be as intuitive - for instance, the differences between the activity in different tasks might not be as strong, and might not be featured in brain regions that (we decided) to plot as close to each other on the circle.\nIn general, when executing a task, a network of brain regions is recruited - or to be cautious, a set of brain regions that we assume are working together for that task. One interesting question to ask is therefore whether different tasks recruit different sets of brain regions. This is a typical question that can be investigated with a dimensionality reduction technique (e.g. clustering).\nLet’s see for instance what happens when we feed the previous results into UMAP.\n\n\nCode\ndo_dimred <- function(df, method) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = 2)\n           pcs <- list(mds$points[,1], mds$points[,2])\n         },\n         umap = {\n           u <- umap(dist(vals))\n           pcs <- list(u[,1], u[,2])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 2, perplexity = 10)\n           pcs <- list(tsne$Y[,1], tsne$Y[,2])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\")\n\n\n\n\n\n\n\n\nThis plot clearly shows that the three tasks recruit different (sub)sets of the originally investigated brain regions. IMHO, this is the clearest representation of our hypotheses - or to be more precise, in this case, of how we constructed our dataset.\nNote however that this plot does not tell us which regions are in the (sub)set recruited by each task. For that, the previous plot can help, and maybe even the initial table, if we were able to select only specific brain regions for our plot and our dimensionality reduction estimation. The latter is something that is implemented in the interactive version below.\nOne last - important - thing that this UMAP plot shows is that the clusters are not completely homogeneous: some participants’s activity for a given task appears in the cluster of a different task. This can be due to many reasons, and it would be nice to investigate why.\nWe can investigate brain activity at the participant level using for instance a simple heatmap like the one below.\n\n\nCode\ndf %>% head(15) %>% \n arrange(task) %>%\n mutate(sub = paste(sub,task,sep = '_')) %>%\n column_to_rownames(var = \"sub\") %>% \n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))\n\n\n\n\n\n\nThis would be particularly useful if we could select all the participants in each cluster using a lasso. This is exactly what is implemented in the interactive version below."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#another-view-of-the-same-results",
    "href": "apps/dimred_app/dimred_app.html#another-view-of-the-same-results",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Another view of the same results",
    "text": "Another view of the same results\nThis visualization shows our main result - which reflects how we actually generate the data: tasks CCC and AAA activate mostly the three top and bottom brain regions, respectively, while task BBB does not appear to activate any of the observed brain regions above baseline.\nConsider that this dataset is very clean, and we are looking only at 6 brain regions, while in reality - in a whole-brain analysis - we look at least at 50+ regions. That is why I prefer to look at the same result with a graphical representation such as the following one.\nNB: in the following graph you can select specific tasks by clicking on the legend\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#reducing-the-dimensionality-for-a-birds-eye-view",
    "href": "apps/dimred_app/dimred_app.html#reducing-the-dimensionality-for-a-birds-eye-view",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Reducing the dimensionality for a bird’s eye view",
    "text": "Reducing the dimensionality for a bird’s eye view\nI find this visualization much easier to inspect than the table above. However,\nHowever, in some cases it might not be as intuitive - for instance, the differences between the activity in different tasks might not be as strong, and might not be featured in brain regions that (we decided) to plot close to each other on the circle.\nIn general, when executing a task, a network of brain regions is recruited - or to be cautious, a set of brain regions that we assume are working together for that task. One interesting question to ask is therefore whether different tasks recruit different sets of brain regions. This is a typical question that can be investigated with a dimensionality reduction technique (e.g. clustering).\nLet’s see for instance what happens when we feed the previous results into UMAP.\n\n\nCode\ndo_dimred <- function(df, method, compX, compY, maxcomp=3) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = maxcomp)\n           pcs <- list(mds$points[,compX], mds$points[,compY])\n         },\n         umap = {\n           u <- umap(dist(vals), n_components = maxcomp)\n           pcs <- list(u[,compX], u[,compY])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 3, perplexity = 10)\n           pcs <- list(tsne$Y[,compX], tsne$Y[,compY])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\", compX = 1, compY = 2)\n\n\n\n\n\n\n\n\nThis plot clearly shows that the three tasks recruit different (sub)sets of the originally investigated brain regions. IMHO, this is the clearest representation of our hypotheses - or to be more precise, in this case, of how we constructed our dataset:\n\nthe dimension of maximum variability in our data is the task (color coded in the plot)\ninstead, the data is substantially homogeneous across participants for each task\n\nNote however that this plot does not tell us which regions are in the (sub)set recruited by each task. For that, the previous plot can help, and maybe even the initial table, if we were able to select only specific brain regions for our plot and our dimensionality reduction estimation. The latter is something that is implemented in the interactive version below.\nOne last - important - thing that this UMAP plot shows is that the clusters are not completely homogeneous: some participants’s activity for a given task appears in the cluster of a different task. This can be due to many reasons, and it would be nice to investigate why.\nWe can investigate brain activity at the participant level using for instance a simple heatmap like the one below.\n\n\nCode\ndf %>% head(15) %>% \n arrange(task) %>%\n # mutate(sub = paste(sub,task,sep = '_')) %>%\n column_to_rownames(var = \"sub\") %>% \n heatmaply(Colv = NA, Rowv = NA, scale=\"none\", colorbar_xanchor = \"left\") %>% \n config(displayModeBar = F) %>% \n layout(font = list(family = \"arial narrow\"))\n\n\n\n\n\n\nThis would be particularly useful if we could select all the participants in each cluster using a lasso. This is exactly what is implemented in the interactive version below."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#a-simple-fmri-experiment",
    "href": "apps/dimred_app/dimred_app.html#a-simple-fmri-experiment",
    "title": "Interactive exploration of neuroimaging results",
    "section": "A simple fMRI experiment",
    "text": "A simple fMRI experiment\nSuppose you want to compare brain activity during the execution of three different tasks: AAA, BBB and CCC. These tasks are behaviourally different, and your hypothesis is that this is reflected in which brain regions are recruited to perform each task. To test this hypothesis you set up an fMRI experiment where 30 participants execute many times each task while being in the scanner (this is an extremely simplified description of an fMRI experiment). The brain activity is recorded in each brain region, but for simplicity here we will focus only on nine of them.\nFor the purpose of showing the utility of our visual exploration of the data, we will generate fictitious data which is in accordance with the hypothesis. Specifically, I will generate summary statistics (mean activity) from 30 participants, showing that some brain regions are more active in task AAA and some in task CCC, while all examined brain regions do not appear to be particularly activated by task BBB.\n\n\nCode\nN = 30\n\nA <- function(mu) rnorm(N, mean = mu)\n\ndf <- tibble(\n task = c(rep(\"AAA\",N), rep(\"BBB\",N), rep(\"CCC\",N)) %>% as.factor(),\n  BA44  = c(A(2), A(2), A(5)),\n  BA45 = c(A(2), A(2), A(5)),\n  BA46  = c(A(2), A(3), A(5)),\n  V1  = c(A(2), A(2), A(2)),\n  V4  = c(A(2), A(2), A(2)),\n  V5  = c(A(2), A(2), A(2)),\n  SI   = c(A(5), A(2), A(2)),\n  SPL  = c(A(5), A(2), A(2)),\n  IPL  = c(A(5), A(3), A(2))\n) %>% \n group_by(task) %>%    # assign participant numbers\n # mutate(sub = paste0(\"sub_\",row_number())) %>%\n mutate(sub = paste0(\"sub_\",row_number(),\"_\",task)) %>%\n relocate(sub) %>%\n ungroup()\n \n\n# # plant an outlier\n# df[c(30,60,90),] %<>%  mutate(across(BA44:IPL, ~ .x + 4))\n\n# define a reusable function to print the table\nshow_table <- function(df) {\n \n BuYlRd <- function(x) {\n   rgb(colorRamp(c(\"#7fb7d7\", \"#ffffbf\", \"#fc8d59\"))(x), maxColorValue = 255)\n }\n \n  reactable(\n    df,\n   resizable = T,\n   # selection = \"multiple\",\n   # onClick = \"select\",\n   defaultColDef = colDef(\n     style = function(value) {\n        vals <- df %>% select(where(is.numeric))\n        if (!is.numeric(value)) return()\n        normalized <- (value - min(vals)) / (max(vals) - min(vals))\n        color <- BuYlRd(normalized)\n        list(background = color)\n      },\n     format = colFormat(digits = 2), minWidth = 50\n   ),\n   style = list(fontFamily = \"Arial narrow\", fontSize = \"13px\")\n  )\n}\n\ndf %>% show_table()\n\n\n\n\n\n\n\nThis is our complete dataset. It is very simplified (and clean) with respect to a real fMRI dataset, but it shows the many levels at which an fMRI can be examined:\n\nacross participants\nacross tasks\nacross brain regions\n\nand of course all the combinations of these levels. For instance we might be interested at the effect of a given task with respect to the other two in a specific brain region or in a specific set of brain regions.\nHere we start to see how quickly the complexity increases for the questions that we might ask even in a simple experiment like this. (It’s here that the interactive exploration will reveal its potential as we will see later).\nAlthough in this table I already color-coded brain the mean activity in each region for each task and each subject, it is quite difficult to have a clear view of the results."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#effect-of-task-in-different-brain-regions-across-participants",
    "href": "apps/dimred_app/dimred_app.html#effect-of-task-in-different-brain-regions-across-participants",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Effect of task in different brain regions across participants",
    "text": "Effect of task in different brain regions across participants\nAt this point we want to check whether the effect we hypothesize is consistent across participants. This is done to achieve a robust estimate of our effect of interest (and of its variability). One basic visualization of this mean result is in the form of a table:\n\n\nCode\ndf_mean <- df %>% \n group_by(task) %>%\n summarise(\n  across(where(is.numeric), ~ mean(.x, na.rm = T)),\n  .groups = \"drop\"\n )\n\n# df_mean %>% show_table()\n\n# pivot to group all the brain regions in a variable\nt_df_mean <- df_mean %>% \n pivot_longer(\n  cols = !task, names_to = \"JU\", values_to = \"Zmean\"\n ) %>% \n pivot_wider(\n  names_from = task, values_from = Zmean\n )\n\nt_df_mean %>% show_table()\n\n\n\n\n\n\n\n\n\nNow the situation appears much more clear than when we looked at the data at the participant level, and indeed reflects how we actually generate the data: tasks CCC and AAA activate mostly the three top and bottom brain regions, respectively, while task BBB does not appear to activate any of the examined brain regions above baseline."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#a-different-visualization",
    "href": "apps/dimred_app/dimred_app.html#a-different-visualization",
    "title": "Interactive exploration of neuroimaging results",
    "section": "A different visualization",
    "text": "A different visualization\nConsider however that here we are looking only at 9 brain regions, while in reality - in a whole-brain analysis - we look at least at 50+ regions (e.g. the 52 Brodmann areas). That is why I prefer to look at the same result with a graphical representation such as the following one.\nNB: in the following graph you can select specific tasks by clicking on the legend\n\n\nCode\ndraw_spiderplot <- function(t_df_mean) {\n  \n  p <- plot_ly(\n    type = 'scatterpolar', mode = 'lines+markers', fill = 'toself', opacity = 0.5\n  ) %>% config(displayModeBar = F)\n  \n  df_vals <- t_df_mean %>% select(-JU)\n  ticks <-  t_df_mean$JU %>% as.character()\n  groups <- df_vals %>% colnames()\n  \n  for (ith_col in 1:length(groups)) {\n    \n    onecol <- df_vals[,ith_col] %>% pull()\n    \n    p <- p %>%\n      add_trace(\n        r = c(onecol, onecol[1]),\n        theta = c(ticks, ticks[1]),\n        name = groups[ith_col],\n        line = list(\n          dash = \"solid\",\n          shape = \"spline\",\n          smoothing = 1,\n          width = 2\n        )\n      ) %>% layout(font = list(family = \"arial narrow\"))\n  }\n  \n  return(p)\n}\n\ndraw_spiderplot(t_df_mean)"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#reducing-the-dimensionality-for-a-sharper-view",
    "href": "apps/dimred_app/dimred_app.html#reducing-the-dimensionality-for-a-sharper-view",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Reducing the dimensionality for a sharper view",
    "text": "Reducing the dimensionality for a sharper view\nI find this visualization much easier to inspect than the table above. However, you might have noticed that we don’t know anymore what is going on at the level of the single participants. Of course are insights on the results so far are purely based on descriptive statistics, and appropriate inferential methods (e.g. ANOVA) will tell us whether the variability across tasks is substantially higher than that between participants. However, it can be useful to have a first look into this by looking at the main trajectories of variability across the entire initial dataset.\nLet’s see for instance what happens when we feed our initial participants-by-brain region table into UMAP.\n\n\nCode\ndo_dimred <- function(df, method, compX, compY, maxcomp=3) {\n  \n  # nsub <- length(df$task)\n  vals <- df %>% select(!task) %>% as.matrix()\n  \n  switch(method,\n         mds = {\n           mds <- cmdscale(dist(vals), eig = T, k = maxcomp)\n           pcs <- list(mds$points[,compX], mds$points[,compY])\n         },\n         umap = {\n           u <- umap(dist(vals), n_components = maxcomp)\n           pcs <- list(u[,compX], u[,compY])\n         },\n         tsne = {\n           tsne <- Rtsne(dist(vals), dims = 3, perplexity = 10)\n           pcs <- list(tsne$Y[,compX], tsne$Y[,compY])\n         }\n  )    \n  \n  df_lowdim <- tibble(\n    task = df$task,\n    sub = df$sub,\n    pc1 = pcs[[1]],\n    pc2 = pcs[[2]],\n  )\n  \n  plot_ly(type = 'scatter', mode = 'markers', source = \"A\") %>%\n    add_trace(\n      data = df_lowdim,\n      x = ~pc1,\n      y = ~pc2,\n      customdata = ~sub,\n      color = ~task,\n      text = ~sub,\n      hoverinfo = 'text'\n      # hovertemplate = paste('%{text}')\n    ) %>% \n    layout(dragmode = \"lasso\") %>% \n    config(displayModeBar = F)\n}\n\ndo_dimred(df,\"umap\", compX = 1, compY = 2)\n\n\n\n\n\n\n\n\nHere each point represents one participant performing one task. The data is grouped in three clusters reflecting - not surprisingly - the difference in brain activity across all particiants and between tasks.\nInterestingly, we see that the brain activity for task BBB in one participant is grouped with a cluster which is mostly populated with activity for task AAA (hover on the orange dot in the green cloud). To inspect this potential anomaly, we can look into the initial data table and inspect the original values. Eventually we can go back to the original fMRI data and - through appropriate examination - decide if something went wrong with the data of this participant, e.g. during data acquisition or pre-processing.\nThis situation is made more clear if we artificially “plant” an anomaly in our data. I will not run this here, but you can download this RMarkdown notebook and run it on your computer. Check out how the UMAP is able to spot the “outliers” which were planted in the data.\n\n\nCode\n# plant an outlier\ngf <- df\ngf[c(29,30,59,60,89,90),] %<>%  mutate(across(BA44:IPL, ~ .x + 4))\n\ndo_dimred(gf,\"umap\", compX = 1, compY = 2)\n\ngf %>% show_table()"
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#bringing-altogether-in-an-interactive-app",
    "href": "apps/dimred_app/dimred_app.html#bringing-altogether-in-an-interactive-app",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Bringing altogether in an interactive app",
    "text": "Bringing altogether in an interactive app\nWe have seen so far how many questions naturally arise even when looking at a intentionally very simplified dataset like the one we generated above.\nIf you read so far you have probably come up with a few other features that you would like to explore in one of the proposed visualization, and see how they affect the other perspectives from which we can look at the data.\nIt is probably clear by now that I am very intrigued by the possibility of exploration offered by dimensionality reduction methods such as UMAP. In the app which is displayed below, that you can open in full screen here, I implemented a few other possibilities that I encourage you to explore:\n\nFor instance, we might want to assess - for data exploration or based on a specific hypothesis - whether the expected effect would hold if you consider only a subset of the brain regions we looked at. This can be done by selecting the regions in the table, and observing the effect in the low-dimensional embedding.\nWe might also want to try to use other dimensionality reduction methoods besides UMAP (check for instance here). In the app, there is a choice of three different methods: Multi-dimensional Scaling (from the stats package), tSNE (from the Rtsne package) and UMAP (from the uwot package).\nAlso, to inspect the original values for each participant in each task, you just have to draw a lasso around the points you are interested in the low-dimensional embedding, and a heatmap of those values will appear in the lower-right corner of the app\n\nHopefully the potential usage of the app are self-explanatory, but if in doubt, check the animated gif at the beginning of this post."
  },
  {
    "objectID": "apps/dimred_app/dimred_app.html#conclusion",
    "href": "apps/dimred_app/dimred_app.html#conclusion",
    "title": "Interactive exploration of neuroimaging results",
    "section": "Conclusion",
    "text": "Conclusion\nThis post has already become much bigger than what I expected. I hope you found it useful or at least interesting, and I would be glad to know what you think about it by dropping me an email.\nI just want to offer two small considerations to conclude.\n\nBuilding an interactive app for data exploration/analysis is something that I dreamt about ever since I started to learn Matlab many years ago. Nowadays with the introduction of libraries such as Shiny for R (and recently also for Python), it has become a task that anyone with an interest in coding can get started with in a relatively short time, and that I personally find satisfying on many different levels. When you get a bit of experience, prototyping a basic app can take as short as one or a few days (as a matter of fact it took me way more time to write this post than the app)\nIn this example I looked only at the participant-level results. Instead in neuroimaging a large amount of time and code is spent on pre-processing the data and checking the results of the many steps involved therein - e.g. checking the outcome of registering one brain to a template, or the whole-brain temporal profile of an fMRI volume after bandpass filtering or de-noising. Although many neuroimaging suite already did a great job in implementing GUIs, you might want to look into other features which are not currently offered, or you might just want to implement an interface for the pre-processing pipelines you wrote. Having this in mind, I believe that libraries like Shiny bring a great potential for developing such personalized tools for researcher in neuroimaging."
  }
]